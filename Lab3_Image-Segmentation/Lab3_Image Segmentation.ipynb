{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mn_VeBhOLwqO"
   },
   "source": [
    "# **Lab3 : Image Segmentation (Histogram of Oriented Gradients & K-Mean Clustering)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 845,
     "status": "ok",
     "timestamp": 1647920384499,
     "user": {
      "displayName": "orachat chitsobhuk",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "06343709387533100222"
     },
     "user_tz": -420
    },
    "id": "uWGpe41UL3EV"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.feature import hog\n",
    "from skimage import measure\n",
    "\n",
    "\n",
    "import glob\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from scipy import spatial\n",
    "\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import os \n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1944,
     "status": "ok",
     "timestamp": 1647920390016,
     "user": {
      "displayName": "orachat chitsobhuk",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "06343709387533100222"
     },
     "user_tz": -420
    },
    "id": "HJnkZ7xQ8dNC",
    "outputId": "856545d2-2035-4839-b5e5-1b3f4cbf742e"
   },
   "outputs": [],
   "source": [
    "### START CODE HERE ###\n",
    "image = None\n",
    "plt.imshow(image)\n",
    "### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histogram of Oriented Gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Blur the image then apply to the [`hog()`](<https://scikit-image.org/docs/stable/api/skimage.feature.html#skimage.feature.hog:~:text=skimage.feature.hog(,%23>)\n",
    "<details>\n",
    "\n",
    "<summary>\n",
    "<font size=\"3\" color=\"orange\">\n",
    "<b>Expected output</b>\n",
    "</font>\n",
    "</summary>\n",
    "\n",
    "- The output should resemble this, but not be identical\n",
    "\n",
    "![image.png](https://raw.githubusercontent.com/Digital-Image-Processing-Laboratory/Image-Processing-Course-2025/refs/heads/main/Lab3_Image-Segmentation/asset/1.png?raw=true)\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 45139,
     "status": "ok",
     "timestamp": 1647920435151,
     "user": {
      "displayName": "orachat chitsobhuk",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "06343709387533100222"
     },
     "user_tz": -420
    },
    "id": "0xUlhoSDoANn",
    "outputId": "5d44cbc3-12ec-4bcb-a08c-bb24957d1473"
   },
   "outputs": [],
   "source": [
    "### START CODE HERE ###\n",
    "blurry_image = cv2.GaussianBlur(None)\n",
    "fd, hog_image = hog(None)\n",
    "\n",
    "\n",
    "\n",
    "### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complete the `HOGSubimageExtractor()`.\n",
    "\n",
    "That extracts Histogram of Oriented Gradients features from sub-images of a larger image. It divides the image into overlapping tiles, computes HOG features for each tile, and stores both the feature vectors and visualizations. The class also provides a method to plot the HOG visualizations.\n",
    "\n",
    "**Attributes:**\n",
    "- `image`: The input image.\n",
    "- `tile_size`: The size of each sub-image to extract.\n",
    "- `stride`: The pixel stride between consecutive sub-images.\n",
    "- `hGrid`: An array of indices representing the starting positions for rows of sub-images.\n",
    "- `wGrid`: An array of indices representing the starting positions for columns of sub-images.\n",
    "- `hog_features`: A list to store the HOG feature vectors for each sub-image.\n",
    "- `hog_images`: A list to store the visualized HOG images for each sub-image (optional).\n",
    "\n",
    "**Methods:**\n",
    "- `extract_hog_features()`: Compute HOG features for each sub-image.\n",
    "- `plot_hog_images()`: Plots the HOG visualization images.\n",
    "- `get_num_grid()`: Return the number of rows and columns in the grid of sub-images.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START CODE HERE ###\n",
    "class HOGSubimageExtractor:\n",
    "    def __init__(self, image, tile_size, stride):\n",
    "        self.image = None\n",
    "        self.tile_size = None\n",
    "        self.stride = None\n",
    "        self.h, self.w, _ = None\n",
    "        self.hGrid = None\n",
    "        self.wGrid = None\n",
    "        self.hog_features = []\n",
    "        self.hog_images = []\n",
    "        self.extract_hog_features()\n",
    "\n",
    "    def extract_hog_features(self):\n",
    "        pass\n",
    "\n",
    "    def plot_hog_images(self):\n",
    "        pass\n",
    "\n",
    "    def get_num_grid(self):\n",
    "        return len(self.hGrid), len(self.wGrid)\n",
    "### END CODE HERE ###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use `HOGSubimageExtractor()` in the cell below.\n",
    "<details>\n",
    "\n",
    "<summary>\n",
    "<font size=\"3\" color=\"orange\">\n",
    "<b>Expected output from hog_extractor.plot_hog_images()</b>\n",
    "</font>\n",
    "</summary>\n",
    "\n",
    "- The output should resemble this, but not be identical\n",
    "\n",
    "![image.png](https://raw.githubusercontent.com/Digital-Image-Processing-Laboratory/Image-Processing-Course-2025/refs/heads/main/Lab3_Image-Segmentation/asset/2.png)\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START CODE HERE ###\n",
    "tile_size = None\n",
    "stride = None\n",
    "hog_extractor = HOGSubimageExtractor(None)\n",
    "num_grid = hog_extractor.get_num_grid()\n",
    "print(f'Number of grids: {num_grid}')\n",
    "hog_extractor.plot_hog_images()\n",
    "### END CODE HERE ###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Mean Clustering\n",
    "Complete the `KMeansCluster()`.\n",
    "Perform K-means clustering on Histogram of Oriented Gradients (HOG) features extracted from an image.\n",
    "**Attriburtes:**\n",
    "- `hog_extractor`: An object responsible for extractin HOG features from an image.\n",
    "- `n_clusters`: The number of clusters to use in K-means.\n",
    "- `cluster_array`: A 2D array representing the cluster assignments for each grid cell.\n",
    "- `all_labels`: A 2D array representing the connected components (objects) identified after clustering.\n",
    "- `bounding_boxes`: A list of tuples containing (object_id, start_coordinates, end_coordinates) for each detected object.\n",
    "\n",
    "**Method:**\n",
    "- `perform_clustering()`: Performs K-means clustering on the HOG features extracted by the hog_extractor object.<br>\n",
    "It then reshapes the cluster assignmentss into a grid and identifies connected components using the `measure.label()` function.\n",
    "- `plot_cluster_and_labels()`: Visualize the cluster assignments and connected components as images using Matplotlib.\n",
    "- `get_bounding_boxes()`: Extracts bounding boxes for each detected object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START CODE HERE ###\n",
    "class KMeansCluster:\n",
    "    def __init__(self, hog_extractor, n_clusters, random_state):\n",
    "        self.hog_extractor = None\n",
    "        self.n_clusters = None\n",
    "        self.random_state = None\n",
    "        self.cluster_array = None\n",
    "        self.all_labels = None\n",
    "        self.bounding_boxes = []\n",
    "        self.perform_clustering()\n",
    "\n",
    "    def perform_clustering(self):\n",
    "        kmeans = KMeans(None)\n",
    "        self.cluster_array = None\n",
    "        self.all_labels = measure.label(None)\n",
    "\n",
    "    def plot_cluster_and_labels(self):\n",
    "        pass\n",
    "\n",
    "    def get_bounding_boxes(self):\n",
    "        pass\n",
    "### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complete the function below. Using [`cv2.rectangle()`](<https://docs.opencv.org/4.x/dc/da5/tutorial_py_drawing_functions.html#:~:text=511%2C511)%2C(255%2C0%2C0)%2C5)-,Drawing%20Rectangle,-To%20draw%20a>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START CODE HERE ###\n",
    "def draw_bbox(image,bboxes):\n",
    "    pass\n",
    "### END CODE HERE ###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use `KMeansCluster()` and `draw_bbox()` in the cell below.\n",
    "<details>\n",
    "\n",
    "<summary>\n",
    "<font size=\"3\" color=\"orange\">\n",
    "<b>Expected output</b>\n",
    "</font>\n",
    "</summary>\n",
    "\n",
    "- The output should resemble this, but not be identical\n",
    "\n",
    "![image-3.png](https://raw.githubusercontent.com/Digital-Image-Processing-Laboratory/Image-Processing-Course-2025/refs/heads/main/Lab3_Image-Segmentation/asset/3.png?raw=true)\n",
    "\n",
    "![image-4.png](https://raw.githubusercontent.com/Digital-Image-Processing-Laboratory/Image-Processing-Course-2025/refs/heads/main/Lab3_Image-Segmentation/asset/4.png?raw=true)\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_cluster = KMeansCluster(hog_extractor)\n",
    "kmeans_cluster.plot_cluster_and_labels()\n",
    "bboxes = kmeans_cluster.get_bounding_boxes()\n",
    "draw_bbox(image,bboxes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment\n",
    "Do the experiment to identify 3 best parameters that produce the perfectly fitting bounding box of the object of interest in the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START CODE HERE ###\n",
    "\n",
    "tile_size = None\n",
    "stride = None\n",
    "\n",
    "\n",
    "\n",
    "### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START CODE HERE ###\n",
    "\n",
    "tile_size = None\n",
    "stride = None\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START CODE HERE ###\n",
    "\n",
    "tile_size = None\n",
    "stride = None\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Question** \n",
    "1. How do the parameters of Gaussian blur, such as kernel size and standard deviation, affect the image processing in the context of k-means clustering?\n",
    "\n",
    "2. How do the configurations of cells per block and pixels per cell influence the effectiveness of object detection in an image?\n",
    "\n",
    "3. What differences can be observed in the clustering results when using smaller sub-images (tiles) compared to larger ones?\n",
    "\n",
    "4. What is the impact on object detection if the labeling step is skipped before applying k-means clustering?\n",
    "\n",
    "5. How does the choice of the number of clusters (K) in k-means clustering affect the image clustering result (right) of an input image (left)? \n",
    "Discuss the trade-offs between too few and too many clusters in accurately representing the test patterns.<br>\n",
    "\n",
    "![q5.jpg](https://raw.githubusercontent.com/Digital-Image-Processing-Laboratory/Image-Processing-Course-2025/refs/heads/main/Lab3_Image-Segmentation/asset/q5.jpg?raw=true)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMiYsoVXc5K/lSh5w7nK2/J",
   "name": "Activity #8.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
